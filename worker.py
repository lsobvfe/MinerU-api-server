# worker.py
import os
import time
import glob # æ·»åŠ  glob å¯¼å…¥
from queue_manager import get_queue, STATUS_DONE, STATUS_FAILED, STATUS_RUNNING, STATUS_UNDONE
from helpers import (
    find_pdf_files, apply_upload_urls, upload_files, 
    poll_for_results, download_and_extract,
    TOKEN, NUM_FILES_TO_UPLOAD # ç¡®ä¿ TOKEN å’Œ NUM_FILES_TO_UPLOAD è¢«å¯¼å…¥
)
import shutil # æ·»åŠ  shutil å¯¼å…¥

# ç¡®ä¿ TOKEN ç¯å¢ƒå˜é‡è®¾ç½®
if not os.environ.get("MINERU_TOKEN"):
    # ä¸´æ—¶è®¾ç½®ï¼Œå®é™…éƒ¨ç½²æ—¶åº”ä½¿ç”¨ .env æˆ–ç³»ç»Ÿç¯å¢ƒå˜é‡
    os.environ["MINERU_TOKEN"] = TOKEN 
    
QUEUE = get_queue()

def process_directory(task_data, task_id):
    """
    å¤„ç†ä¸€ä¸ªç›®å½•ä»»åŠ¡ï¼Œç›´åˆ°è¯¥ç›®å½•ä¸‹æ‰€æœ‰ PDF æ–‡ä»¶å¤„ç†å®Œæ¯•ã€‚
    """
    base_dir = task_data.get("directory_path") 

    print(f"\n=======================================================")
    print(f"ğŸ”¥ WORKER START: Processing Task ID {task_id} in Dir: {base_dir}")
    print(f"=======================================================")

    processed_count = 0
    # è¿™é‡Œåº”è¯¥è®¡ç®—å°šæœªå¤„ç†çš„ PDF æ–‡ä»¶æ€»æ•°ï¼Œè€Œä¸æ˜¯ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶
    # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬æš‚æ—¶ä¿ç•™è¿™ä¸ªè®¡æ•°æ–¹å¼ï¼Œä½†éœ€æ³¨æ„å…¶å¯èƒ½ä¸å®Œå…¨å‡†ç¡®
    total_files_in_dir = len(glob.glob(os.path.join(base_dir, "*.pdf")))
    
    # å®šä¹‰ç»“æœå­ç›®å½•
    processed_dir_path = os.path.join(base_dir, "processed")
    markdown_dir_path = os.path.join(base_dir, "markdown")
    done_dir_path = os.path.join(base_dir, "done") # ç”¨äºå­˜æ”¾å·²å¤„ç†çš„åŸå§‹ PDF

    os.makedirs(processed_dir_path, exist_ok=True)
    os.makedirs(markdown_dir_path, exist_ok=True)
    os.makedirs(done_dir_path, exist_ok=True)
    
    # ç›®å½•çº§åˆ«å¾ªç¯ï¼šåªè¦ç›®å½•ä¸­è¿˜æœ‰æœªå¤„ç†çš„æ–‡ä»¶ï¼Œå°±ç»§ç»­å¾ªç¯
    while True:
        # 1. æŸ¥æ‰¾å¾…å¤„ç†çš„æ–‡ä»¶
        # æ”¹è¿›ï¼šfind_pdf_files åº”è¯¥åªè¿”å›æœªåœ¨ 'done' ç›®å½•ä¸­çš„æ–‡ä»¶
        current_pdf_files = [f for f in glob.glob(os.path.join(base_dir, "*.pdf")) if not os.path.exists(os.path.join(done_dir_path, os.path.basename(f)))]
        
        file_list = find_pdf_files(base_dir, NUM_FILES_TO_UPLOAD)
        # è¿›ä¸€æ­¥è¿‡æ»¤ï¼Œç¡®ä¿åªå¤„ç†é‚£äº›ä¸åœ¨ done_dir_path ä¸­çš„æ–‡ä»¶
        file_list = [f for f in file_list if not os.path.exists(os.path.join(done_dir_path, f["name"]))]
        
        if not file_list:
            print(f"\nâœ… ç›®å½• '{base_dir}' ä¸­çš„æ‰€æœ‰æ–‡ä»¶å·²å¤„ç†å®Œæ¯• (å…±å¤„ç† {processed_count} ä¸ªæ–‡ä»¶). ")
            return True # ä»»åŠ¡æˆåŠŸå®Œæˆ

        print(f"\n--- Found {len(file_list)} files for current batch ({len(current_pdf_files) - len(file_list)} remaining in directory for next batch) ---")

        # 2. ç”³è¯·ä¸Šä¼ é“¾æ¥
        batch_id, file_list_with_urls = apply_upload_urls(file_list)
        if not batch_id:
            print("Batch ID è·å–å¤±è´¥ï¼Œè·³è¿‡å½“å‰æ‰¹æ¬¡...")
            return False # æ ‡è®°ä»»åŠ¡å¤±è´¥

        # 3. ä¸Šä¼ æ–‡ä»¶
        if not upload_files(file_list_with_urls):
            print("æ–‡ä»¶ä¸Šä¼ å¤±è´¥ï¼Œè·³è¿‡å½“å‰æ‰¹æ¬¡...")
            return False

        # 4. è½®è¯¢ç»“æœ
        final_results = poll_for_results(batch_id)

        if final_results:
            # 5. ä¸‹è½½ã€è§£å‹å’Œå¤„ç†æ–‡ä»¶
            download_and_extract(final_results, processed_dir_path, markdown_dir_path)
            
            # 6. æ¸…ç†æ–‡ä»¶ï¼šå°†åŸå§‹ PDF æ–‡ä»¶ç§»åŠ¨åˆ° done å­ç›®å½•
            successful_files_in_batch = []
            for res in final_results:
                if res.get("state") == "done":
                    # ä»åŸå§‹ file_list ä¸­æ‰¾åˆ°å¯¹åº”çš„æ–‡ä»¶è·¯å¾„
                    original_file_name = res.get("file_name")
                    for f_detail in file_list:
                        if f_detail["name"] == original_file_name:
                            successful_files_in_batch.append(f_detail["path"])
                            break
            
            for path in successful_files_in_batch:
                try:
                    shutil.move(path, os.path.join(done_dir_path, os.path.basename(path)))
                    processed_count += 1
                    print(f"  âœ… å·²å°† '{os.path.basename(path)}' ç§»åŠ¨åˆ° 'done' ç›®å½•ã€‚")
                except Exception as e:
                    print(f"  âŒ æ— æ³•ç§»åŠ¨æ–‡ä»¶ {path}: {e}")
            
            print(f"--- æ‰¹æ¬¡å¤„ç†å®Œæˆã€‚æˆåŠŸå¤„ç† {len(successful_files_in_batch)} ä¸ªæ–‡ä»¶ã€‚---")

        else:
            print("è½®è¯¢ç»“æœå¤±è´¥ï¼Œè·³è¿‡å½“å‰æ‰¹æ¬¡...")
            return False # æ ‡è®°ä»»åŠ¡å¤±è´¥

        # å°æ†©ä¸€ä¸‹ï¼Œé¿å…è¿ç»­é«˜é¢‘æ“ä½œ
        time.sleep(2) 

    return False # ä»»åŠ¡å¤±è´¥é€€å‡ºï¼Œç†è®ºä¸Šåœ¨ä¸Šé¢çš„ return å¤„å·²ç»é€€å‡º
    
def worker_loop():
    """Workerä¸»å¾ªç¯ï¼Œä¸æ–­ä»é˜Ÿåˆ—ä¸­å–ä»»åŠ¡"""
    print("--- Mineru OCR Worker å¯åŠ¨ ---")
    while True:
        try:
            task_item = QUEUE.get_message() # ä½¿ç”¨ get_message è·å–ä»»åŠ¡

            if task_item:
                task_id = task_item['id']
                task_data = task_item['data']
                
                success = process_directory(task_data, task_id)
                
                # æ ¹æ®ç»“æœæ›´æ–°æœ€ç»ˆçŠ¶æ€
                if success:
                    QUEUE.complete_message(task_id)
                    print(f"âœ… Task ID {task_id} å®Œæˆã€‚")
                else:
                    QUEUE.fail_message(task_id)
                    print(f"âŒ Task ID {task_id} å¤±è´¥ã€‚")
            else:
                print("ç­‰å¾…ä»»åŠ¡... (5s)")
                time.sleep(5) # æ²¡æœ‰ä»»åŠ¡æ—¶ç­‰å¾…ä¸€æ®µæ—¶é—´

        except Exception as e:
            print(f"Worker å‘ç”Ÿè‡´å‘½é”™è¯¯: {e}")
            time.sleep(10) # é¿å…é”™è¯¯å¾ªç¯

if __name__ == '__main__':
    worker_loop()